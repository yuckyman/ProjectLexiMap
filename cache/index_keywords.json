{
  "1": [
    "cross-validation",
    "agents",
    "clustering algorithms",
    "hierarchical clustering algorithms",
    "importance of data over",
    "supervised learning",
    "unsupervised learning",
    "visualization algorithms",
    "anomaly detection",
    "restricted boltzmann machines",
    "rbms",
    "association rule learning",
    "attributes",
    "batch learning",
    "better life index",
    "causal models",
    "classification mlps",
    "corpus development",
    "data mismatch",
    "importance of over algorithms",
    "noisy data",
    "deep belief networks",
    "dbns",
    "overfitting",
    "development sets",
    "dev sets",
    "feature engineering",
    "feature extraction",
    "feature selection",
    "features",
    "final trained models",
    "fitness functions",
    "fully-specified model architecture",
    "generalization error",
    "hold outs",
    "holdout validation",
    "hyperparameters",
    "hyperparameter tuning",
    "learning rate",
    "incremental learning",
    "inference",
    "instance-based learning",
    "k-nearest neighbors regression",
    "labels",
    "linear models",
    "classification with",
    "machine learning",
    "ml",
    "testing and validating",
    "measure of similarity",
    "mini-batches",
    "model parameters",
    "model selection",
    "model-based learning",
    "training",
    "no free lunch",
    "nfl",
    "novelty detection",
    "offline learning",
    "online learning",
    "optical character recognition",
    "ocr",
    "out-of-core learning",
    "out-of-sample error",
    "penalties",
    "policies",
    "prediction problems",
    "regression problems",
    "regularization",
    "reinforcement learning",
    "rl",
    "responsibilities",
    "clustering",
    "rewards",
    "sampling bias",
    "sampling noise",
    "linear model",
    "semi-supervised learning",
    "spam filters",
    "test sets",
    "train-dev sets",
    "training data",
    "irrelevant features",
    "nonrepresentative",
    "poor quality",
    "underfitting",
    "training instances",
    "training samples",
    "training sets",
    "algorithms covered",
    "common tasks",
    "utility functions",
    "validation sets"
  ],
  "2": [
    "cross-validation",
    "evaluating",
    "average absolute deviation",
    "california housing prices dataset",
    "mnist dataset",
    "components",
    "correlation coefficient",
    "mean absolute error",
    "mae",
    "downloading",
    "geographical data",
    "data preparation",
    "custom transformers",
    "data cleaning",
    "feature scaling",
    "handling text and categorical attributes",
    "transformation pipelines",
    "data snooping bias",
    "attribute combinations",
    "computing correlations",
    "test training and exploration sets",
    "duck typing",
    "dummy attributes",
    "embedding",
    "estimators",
    "euclidean norm",
    "data downloading",
    "data visualization",
    "framing the problem",
    "launching monitoring and maintaining",
    "machine learning project checklist",
    "model fine-tuning",
    "model selection and training",
    "project goals",
    "selecting performance measure",
    "verifying assumptions",
    "exploration sets",
    "folds",
    "histograms",
    "hyperparameter tuning",
    "isolated environments",
    "k-fold cross-validation",
    "labels",
    "machine learning",
    "ml",
    "manhattan norm",
    "rmse",
    "min-max scaling",
    "model selection",
    "fine-tuning",
    "training",
    "multiple regression problems",
    "multivariate regression problems",
    "normalization",
    "dense arrays",
    "installing",
    "serializing large arrays",
    "one-hot encoding",
    "one-hot vectors",
    "pearsons r",
    "pipelines",
    "predictors",
    "univariate regression problems",
    "representation learning",
    "root mean square error",
    "converting text to numbers",
    "dataset dictionary structure",
    "design principles",
    "gridsearchcv",
    "k-fold cross-validation feature",
    "mean_squared_error function",
    "missing value handling",
    "saving models",
    "splitting datasets into subsets",
    "stratified sampling",
    "transformation sequences",
    "transformers and",
    "sparse matrix",
    "standard correlation coefficient",
    "standardization",
    "tail-heavy histograms",
    "deploying on ai platforms",
    "test sets",
    "example project",
    "transformations",
    "workspace creation"
  ],
  "3": [
    "accuracy",
    "cross-validation",
    "area under the curve",
    "auc",
    "binary classifiers",
    "error analysis",
    "multiclass classification",
    "multilabel classification",
    "multioutput classification",
    "performance measures",
    "confusion matrix",
    "skewed datasets",
    "decision function",
    "f1 score",
    "false positive rate",
    "fpr",
    "folds",
    "gradient descent",
    "gd",
    "stochastic gradient descent",
    "harmonic mean",
    "k-fold cross-validation",
    "approaches to training",
    "precision",
    "recall",
    "roc curve",
    "multinomial classifiers",
    "randint function",
    "one-versus-all",
    "ova",
    "one-versus-one",
    "ovo",
    "one-versus-the-rest",
    "ovr",
    "online learning",
    "sgd",
    "receiver operating characteristic",
    "roc",
    "computing classifier metrics",
    "cross_val_score function",
    "sgdclassifier class",
    "sensitivity",
    "training models",
    "true negative rate",
    "tnr",
    "true positive rate",
    "tpr"
  ],
  "4": [
    "logistic",
    "sigmoid",
    "argmax operator",
    "batch gradient descent",
    "bias terms",
    "biasvariance trade-off",
    "calculus",
    "large margin classification",
    "linear svm classification",
    "closed-form solution",
    "column vectors",
    "convergence",
    "convex function",
    "cross-entropy loss",
    "log loss",
    "mean squared error",
    "iris dataset",
    "decision boundaries",
    "computational complexity",
    "early stopping",
    "elastic net",
    "epochs",
    "feature vector",
    "full gradient descent",
    "global minimum",
    "gradient descent",
    "gd",
    "mini-batch gradient descent",
    "stochastic gradient descent",
    "learning rate",
    "identity matrix",
    "independent and identically distributed",
    "iid",
    "random initialization",
    "intercept terms",
    "kullbackleibler divergence",
    "lasso regression",
    "learning curves",
    "learning schedules",
    "linear algebra",
    "linear regression model",
    "approaches to training",
    "normal equation",
    "local minimum",
    "log-odds",
    "logistic regression",
    "estimating probabilities",
    "softmax regression",
    "training and cost function",
    "logit",
    "rmse",
    "mini-batches",
    "multinomial logistic regression",
    "normalized exponential",
    "inv function",
    "sgd",
    "parameter matrix",
    "parameter space",
    "parameter vector",
    "partial derivatives",
    "polynomial regression",
    "linear regression",
    "ridge regression",
    "regularization terms",
    "regularized linear models",
    "root mean square error",
    "linear regression",
    "simulated annealing",
    "singular value decomposition",
    "svd",
    "softmax function",
    "subgradient vector",
    "support vector machines",
    "svms",
    "tikhonov regularization",
    "tolerance",
    "feature vectors",
    "parameter vectors",
    "subgradient vectors"
  ],
  "5": [
    "hard margin classification",
    "nonlinear svm classification",
    "soft margin classification",
    "constrained optimization",
    "hinge loss",
    "feature scaling",
    "decision trees",
    "training and visualizing",
    "dual problem",
    "gaussian radial basis function",
    "rbf",
    "hinge loss function",
    "hyperplanes",
    "kernel trick",
    "kernelized svm",
    "kernels",
    "landmarks",
    "levenshtein distance",
    "liblinear library",
    "libsvm library",
    "machine learning",
    "ml",
    "margin violations",
    "mercers conditions",
    "mercers theorem",
    "online svms",
    "polynomial features",
    "polynomial kernels",
    "primal problem",
    "quadratic programming",
    "qp",
    "radial basis function",
    "svm regression",
    "svm classification classes",
    "svm models",
    "tolerance hyperparameter",
    "sigmoid kernel",
    "similarity functions",
    "slack variables",
    "string kernels",
    "string subsequence kernel",
    "subderivatives",
    "decision function and prediction",
    "training objective",
    "support vectors"
  ],
  "6": [
    "cart training algorithm",
    "greedy algorithms",
    "binary trees",
    "black box models",
    "chi-squared test",
    "classification and regression tree",
    "cart",
    "voting classifiers",
    "mean squared error",
    "decision trees",
    "computational complexity",
    "estimating class probabilities",
    "gini impurity versus entropy",
    "instability drawbacks",
    "making predictions",
    "regression tasks",
    "regularization hyperparameters",
    "ensemble learning",
    "random forests",
    "ensemble methods",
    "ensembles",
    "entropy impurity measure",
    "gini impurity measure",
    "impurity",
    "information theory",
    "instability",
    "leaf nodes",
    "majority-vote predictions",
    "parametric versus nonparametric",
    "white versus black box",
    "nonparametric models",
    "np-complete problem",
    "null hypothesis",
    "p-value",
    "parametric models",
    "prediction problems",
    "pruning",
    "hyperparameters for decision trees",
    "root nodes",
    "decisiontreeregressor class",
    "max_depth hyperparameter",
    "presorting data with",
    "random_state hyperparameter",
    "shannons information theory",
    "statistical significance",
    "training set rotation",
    "white box models",
    "wisdom of the crowd"
  ],
  "7": [
    "adaboost",
    "adaptive boosting",
    "bagging and pasting",
    "out-of-bag evaluation",
    "in scikit-learn",
    "blenders",
    "gradient boosting",
    "boosting",
    "adaboost classifiers",
    "extra-trees classifier",
    "voting classifiers",
    "dimensionality reduction",
    "decision stumps",
    "random forests",
    "random patches and random subspaces",
    "stacking",
    "extremely randomized trees ensemble",
    "gradient boosted regression trees",
    "gbrt",
    "gradient tree boosting",
    "hard voting classifiers",
    "high-dimensional training sets",
    "hypothesis boosting",
    "law of large numbers",
    "majority-vote classifiers",
    "meta learners",
    "extra-trees",
    "feature importance",
    "shrinkage technique",
    "residual errors",
    "samme",
    "stagewise additive modeling using a multiclass exponential loss function",
    "adaboost version",
    "extratreesclassifier class",
    "feature importance scoring",
    "gbrt ensemble training",
    "incremental training",
    "shrinkage",
    "soft voting",
    "stacked generalization",
    "statistical mode",
    "stochastic gradient boosting",
    "strong learners",
    "training sets",
    "weak learners",
    "xgboost"
  ],
  "8": [
    "isomap algorithm",
    "randomized pca algorithm",
    "unsupervised learning",
    "compression",
    "curse of dimensionality",
    "compressing",
    "decompressing",
    "reconstruction error",
    "reducing dimensionality",
    "dimensionality reduction",
    "decompression",
    "lle",
    "locally linear embedding",
    "pca",
    "principal component analysis",
    "explained variance ratio",
    "feature maps",
    "feature space",
    "incremental pca",
    "ipca",
    "inverse transformation",
    "kernel pca",
    "kpca",
    "kernel trick",
    "kernels",
    "linear discriminant analysis",
    "lda",
    "manifold assumption",
    "manifold hypothesis",
    "manifold learning",
    "multidimensional scaling",
    "mds",
    "nonlinear dimensionality reduction",
    "nldr",
    "array_split function",
    "memmap class",
    "svd function",
    "original space",
    "choosing dimension number",
    "for compression",
    "incremental",
    "preserving variance",
    "principal component axis",
    "projecting down to d dimensions",
    "randomized",
    "using scikit-learn",
    "pre-images",
    "projection",
    "random projections",
    "randomized pca",
    "reconstruction pre-images",
    "automatic reconstruction with",
    "full svd approach",
    "incrementalpca class",
    "kernelpca class",
    "pcang",
    "singular value decomposition",
    "svd",
    "subspace",
    "t-distributed stochastic neighbor embedding",
    "t-sne",
    "training instances",
    "preserving"
  ],
  "9": [
    "accelerated k-means",
    "active learning",
    "affinity",
    "affinity propagation",
    "agglomerative clustering",
    "akaike information criterion",
    "aic",
    "birch algorithm",
    "clustering algorithms",
    "expectation-maximization",
    "em",
    "for anomaly detection",
    "isolation forest algorithm",
    "k-means algorithm",
    "lloydforgy algorithm",
    "mean-shift algorithm",
    "one-class svm algorithm",
    "alpha channels",
    "anomaly detection",
    "using clustering",
    "using gaussian mixtures",
    "bayesian gaussian mixture models",
    "bayesian information criterion",
    "bic",
    "black box stochastic variational inference",
    "bbsvi",
    "categorical distribution",
    "centroids",
    "classification mlps",
    "additional algorithms",
    "dbscan",
    "for image segmentation",
    "k-means",
    "for preprocessing",
    "for semi-supervised learning",
    "color segmentation",
    "semantic segmentation",
    "core instances",
    "customer segmentation",
    "analyzing through clustering",
    "preprocessing",
    "density estimation",
    "evidence lower bound",
    "elbo",
    "expectation step",
    "fast-mcd",
    "minimum covariance determinant",
    "fraud detection",
    "gaussian mixture model",
    "gmm",
    "additional algorithms for anomaly and novelty detection",
    "selecting cluster number",
    "variants",
    "hard clustering",
    "hierarchical dbscan",
    "hdbscan",
    "image segmentation",
    "inertia",
    "centroid initialization methods",
    "inliers",
    "instance segmentation",
    "accelerated and mini-batch",
    "hard and soft clustering",
    "optimal cluster number",
    "preprocessing with",
    "proposed improvement to",
    "scaling input features",
    "label propagation",
    "labels",
    "latent variables",
    "likelihood function",
    "lloyd-forgy algorithm",
    "local outlier factor",
    "lof",
    "maximization step",
    "maximum a-posteriori",
    "map",
    "maximum likelihood estimate",
    "mle",
    "mean field variational inference",
    "mini-batch k-means",
    "novelty detection",
    "observed variables",
    "outlier detection",
    "p",
    "posterior",
    "prior",
    "anomaly and novelty detection",
    "probability density function",
    "pdf",
    "recommender systems",
    "responsibilities",
    "clustering",
    "search engines",
    "silhouette coefficient",
    "silhouette diagram",
    "silhouette score",
    "soft clustering",
    "spectral clustering",
    "theoretical information criterion",
    "uncertainty sampling",
    "gaussian mixtures model",
    "variational inference",
    "variational parameters"
  ],
  "10": [
    "hyperbolic tangent",
    "tanh",
    "logistic",
    "sigmoid",
    "rectified linear unit function",
    "relu",
    "softmax",
    "softplus",
    "fine-tuning hyperparameters",
    "from biological to artificial neurons",
    "implementing mlps with keras",
    "artificial neurons",
    "automatic differentiation",
    "autodiff",
    "automl",
    "backpropagation",
    "batch size",
    "bias neurons",
    "biological neural networks",
    "bnn",
    "biological neurons",
    "break the symmetry",
    "callbacks",
    "chain rule",
    "classification mlps",
    "image classifiers using sequential apis",
    "multitask classification",
    "connectionism",
    "cross-entropy loss",
    "log loss",
    "mean absolute error",
    "mae",
    "mean squared error",
    "fashion mnist dataset",
    "deep neural networks",
    "dnns",
    "deep neuroevolution",
    "dense layer",
    "dynamic models",
    "epochs",
    "event files",
    "exclusive or",
    "xor",
    "feedforward neural networks",
    "fnns",
    "forward pass",
    "fully connected layer",
    "functional api",
    "hdf5 format",
    "heaviside step function",
    "hebbs rule",
    "hebbian learning",
    "hidden layers in mlps",
    "neurons per hidden layer",
    "huber loss",
    "hyperas",
    "hyperband",
    "hyperbolic tangent function",
    "hyperopt",
    "fine-tuning for neural networks",
    "learning rate",
    "python libraries for optimization",
    "image classification",
    "using sequential api",
    "input layers",
    "input neurons",
    "complex architectures",
    "implementing mlps with",
    "kerascallbacks package",
    "loading datasets with",
    "multibackend keras",
    "saving and restoring models",
    "using code examples from kerasio",
    "keras tuner",
    "kopt library",
    "dense",
    "fully connected",
    "hidden layer",
    "input layer",
    "output layer",
    "logical computations",
    "microsoft cognitive toolkit",
    "cntk",
    "complex using functional api",
    "dynamic using subclassing api",
    "saving and restoring",
    "using callbacks",
    "using tensorboard for visualization",
    "regression mlps",
    "multiple outputs",
    "from biological to artificial",
    "logical computations with",
    "per hidden layer",
    "nonsequential neural networks",
    "installing",
    "output layers",
    "parameter efficiency",
    "perceptron",
    "perceptron convergence theorem",
    "propositional logic",
    "pytorch library",
    "regression mlps using sequential api",
    "restoring models",
    "reverse-mode autodiff",
    "perceptron class",
    "scikit-optimize",
    "tensorflow",
    "image classifiers",
    "regression mlp",
    "sklearn-deap",
    "softmax function",
    "softplus activation function",
    "spearmint library",
    "step function",
    "subclassing api",
    "summaries",
    "symmetry breaking in backpropagation",
    "talos library",
    "tensorboard",
    "tensorflow playground",
    "pytorch library and",
    "tfkeras",
    "tfsummary package",
    "theano",
    "threshold logic unit",
    "tlu",
    "transfer learning",
    "wide deep neural networks"
  ],
  "11": [
    "1cycle scheduling",
    "exponential linear unit",
    "elu",
    "logistic",
    "sigmoid",
    "nonsaturating",
    "scaled exponential linear unit",
    "selu",
    "adagrad",
    "adam and nadam optimization",
    "adaptive learning rate",
    "adaptive moment estimation",
    "restricted boltzmann machines",
    "rbms",
    "batch normalization",
    "bn",
    "training sparse models",
    "overfitting",
    "default configuration",
    "faster optimizers",
    "reusing pretrained layers",
    "vanishingexploding gradients problems",
    "dropout",
    "dying relus problem",
    "exploding gradients problem",
    "exponential scheduling",
    "fan-infan-out numbers",
    "first-order partial derivatives",
    "jacobians",
    "glorot and he initialization",
    "gradient clipping",
    "greedy layer-wise pretraining",
    "he initialization",
    "lecun initialization",
    "xavier initialization",
    "keep probability",
    "implementing batch normalization with",
    "implementing dropout",
    "transfer learning with",
    "reusing pretrained",
    "leaky relu function",
    "learning rate scheduling",
    "learning schedules",
    "max-norm regularization",
    "momentum optimization",
    "momentum vector",
    "monte carlo",
    "mc",
    "nesterov accelerated gradient",
    "nag",
    "nesterov momentum optimization",
    "nonsaturating activation functions",
    "normalization",
    "creating faster",
    "first- and second-order partial derivatives",
    "rmsprop",
    "avoiding through regularization",
    "parametric leaky relu",
    "prelu",
    "performance scheduling",
    "piecewise constant scheduling",
    "power scheduling",
    "on auxiliary tasks",
    "unsupervised pretraining",
    "randomized leaky relu",
    "rrelu",
    "avoiding overfitting through",
    "second-order partial derivatives",
    "hessians",
    "self-normalization",
    "self-supervised learning",
    "skip connections",
    "smoothing term",
    "sparse models",
    "tensorflow model optimization toolkit",
    "tf-mot",
    "versions covered",
    "tensorflow custom models and training",
    "implementing learning rate scheduling",
    "tfkeras",
    "transfer learning",
    "wall time"
  ],
  "12": [
    "accuracy",
    "autographs",
    "automatic differentiation",
    "autodiff",
    "computation graphs",
    "mean squared error",
    "activation functions initializers regularizers and constraints",
    "computing gradients using autodiff",
    "layers",
    "loss functions",
    "losses and metrics",
    "metrics",
    "models",
    "saving and loading",
    "training loops",
    "loading and preprocessing with tensorflow",
    "eager executioneager mode",
    "embedding",
    "features",
    "first in first out",
    "fifo",
    "graph mode",
    "huber loss",
    "just-in-time",
    "jit",
    "low-level api",
    "kernels",
    "see cost functions",
    "locating papers on",
    "custom with tensorflow",
    "using tensorflow like",
    "queues",
    "ragged tensors",
    "reconstruction loss",
    "residual blocks",
    "sets",
    "sparse tensors",
    "stateful metrics",
    "streaming metrics",
    "string tensors",
    "symbolic tensors",
    "tensor arrays",
    "tensorflow hub",
    "tensorflow lite",
    "tensorflow basics of architecture",
    "benefits xvi",
    "community support",
    "getting help",
    "library ecosystem",
    "operating system compatibility",
    "tensorflow data loading and preprocessing",
    "tensorflow functions and graphs",
    "autograph and tracing",
    "tf function rules",
    "tensors",
    "rules",
    "tpus",
    "tensor processing units",
    "type conversions",
    "variables"
  ],
  "13": [
    "bag of words",
    "encoding using embeddings",
    "encoding using one-hot vectors",
    "chaining transformations",
    "helper function creation",
    "prefetching",
    "preprocessing",
    "shuffling",
    "using datasets with tfkeras",
    "tensorflow data api",
    "prefetching data",
    "preprocessing data",
    "shuffling data",
    "using datasets with tfkeras",
    "datasets",
    "embedding",
    "embedding matrix",
    "helper functions",
    "preprocessing layers",
    "lists of lists using sequenceexample protobuf",
    "memory bandwidth",
    "cnns",
    "one-hot vectors",
    "out-of-vocabulary",
    "oov",
    "pipelines",
    "protocol buffers",
    "protobufs",
    "representation learning",
    "sequenceexample protobuf",
    "shuffling-buffer approach",
    "tensorflow extended",
    "tfx",
    "data api",
    "preprocessing input features",
    "tensorflow datasets",
    "tfds",
    "tf transform",
    "tfrecord format",
    "term-frequency inverse-document-frequency",
    "tf-idf",
    "tf datasets",
    "tftransform",
    "tfkeras",
    "compressed tfrecord files",
    "lists of lists using sequenceexample protobuf",
    "loading and parsing examples",
    "tensorflow protobufs",
    "trainingserving skew",
    "chaining",
    "vocabulary",
    "voice recognition",
    "word embeddings"
  ],
  "14": [
    "softmax",
    "adversarial learning",
    "alexnet",
    "anchor boxes",
    "autonomous driving systems",
    "average pooling layer",
    "average precision",
    "ap",
    "bottleneck layers",
    "bounding box priors",
    "classification and localization",
    "color channels",
    "convolution kernels",
    "convolutional layer",
    "filters",
    "memory requirements",
    "stacking multiple feature maps",
    "tensorflow implementation",
    "architecture of visual cortex",
    "cnn architectures",
    "object detection",
    "pooling layer",
    "pretrained models for transfer learning",
    "pretrained models from keras",
    "resnet-34 using keras",
    "semantic segmentation",
    "data augmentation",
    "depth concat layer",
    "depth radius",
    "depthwise separable convolution",
    "equivariance",
    "feature maps",
    "fully convolutional networks",
    "fcns",
    "global average pooling layer",
    "googlenet",
    "image generation",
    "instance segmentation",
    "invariance",
    "implementing resnet-34 with",
    "using pretrained models from",
    "lenet-5",
    "local response normalization",
    "localization",
    "mask r-cnn",
    "max pooling layer",
    "mean average precision",
    "map",
    "mean average precision",
    "rnns",
    "non-max suppression",
    "you only look once",
    "yolo",
    "objectness output",
    "pooling kernel",
    "pretraining",
    "models from keras",
    "recurrent neural networks",
    "rnns",
    "region proposal network",
    "rpn",
    "residual learning",
    "residual units",
    "resnet",
    "residual network",
    "resnet-34 cnn",
    "se block",
    "se-inception",
    "se-resnet",
    "senet",
    "squeeze-and-excitation network",
    "separable convolution",
    "sequences",
    "shortcut connections",
    "single-shot learning",
    "skip connections",
    "softmax function",
    "stride",
    "subsampling",
    "convolution operations",
    "convolutional layers",
    "transfer learning",
    "transposed convolutional layer",
    "upsampling layer",
    "vggnet",
    "wordtrees",
    "xception",
    "extreme inception",
    "zero padding",
    "zf net"
  ],
  "15": [
    "1d convolutional layers",
    "recurrent",
    "autoregressive integrated moving average",
    "arima",
    "backpropagation through time",
    "bptt",
    "basic cells",
    "causal models",
    "chatbots",
    "mean squared error",
    "decoders",
    "differencing",
    "encoders",
    "encoderdecoder model",
    "forecasting",
    "forget gate",
    "gate controllers",
    "gated recurrent unit",
    "gru",
    "imputation",
    "input and output sequences",
    "input gate",
    "layer normalization",
    "1d convolutional layer",
    "logit regression",
    "see logistic regression",
    "long sequences short-term memory problems",
    "unstable gradients problem",
    "long short-term memory",
    "lstm",
    "memory cells",
    "sequence-to-sequence models",
    "training",
    "multivariate time series",
    "naive forecasting",
    "natural language processing",
    "nlp",
    "recurrent neurons",
    "output gate",
    "peephole connections",
    "forecasting time series",
    "handling long sequences",
    "recurrent neurons and layers",
    "stateless and stateful",
    "sequence-to-vector networks",
    "handling long",
    "input and output",
    "short-term memory problems",
    "time series data",
    "baseline metrics",
    "deep rnns",
    "forecasting several steps ahead",
    "simple rnns",
    "time step",
    "turing test",
    "univariate time series",
    "unrolling the network through time",
    "vector-to-sequence networks",
    "wavenet",
    "weighted moving average model"
  ],
  "16": [
    "softmax",
    "additive attention",
    "attention mechanism",
    "explainability and",
    "transformer architecture",
    "visual attention",
    "autoencoders",
    "bahdanau attention",
    "beam search",
    "beam width",
    "bidirectional recurrent layers",
    "bidirectional rnns",
    "byte-pair encoding",
    "character rnns",
    "char-rnns",
    "building and training",
    "chopping sequential datasets",
    "generating shakespearean text",
    "splitting sequential datasets",
    "stateful rnns and",
    "training dataset creation",
    "concatenative attention",
    "conditional probability",
    "loss functions",
    "flat datasets",
    "google news 7b corpus",
    "internet movie database",
    "nested datasets",
    "dense vectors",
    "dot product",
    "embedded reber grammars",
    "encoderdecoder model",
    "end-of-sequence",
    "eos",
    "entailment",
    "explainability",
    "stylegans",
    "language models",
    "latent representations",
    "bidirectional recurrent layer",
    "masked multi-head attention layer",
    "multi-head attention layer",
    "scaled dot-product attention layer",
    "see cost functions",
    "mask tensors",
    "masked language model",
    "mlm",
    "masking",
    "modules",
    "multiplicative attention",
    "natural language processing",
    "nlp",
    "attention mechanisms",
    "encoderdecoder network",
    "generating text using character rnns",
    "sentiment analysis",
    "neural machine translation",
    "nmt",
    "next sentence prediction",
    "nsp",
    "positional encodings",
    "reusing pretrained embeddings",
    "generating text using character rnns",
    "stateless and stateful",
    "regular expressions",
    "sampled softmax technique",
    "self-attention mechanism",
    "sentence encoders",
    "softmax function",
    "start of sequence",
    "sos",
    "temperature",
    "tensorflow addons",
    "tensorflow hub",
    "testing and validation",
    "text generation",
    "tftext library",
    "tokenization",
    "truncated backpropagation through time",
    "word tokenization",
    "zero-shot learning",
    "zsl"
  ],
  "17": [
    "adaptive instance normalization",
    "adain",
    "adversarial learning",
    "affine transformations",
    "autoencoders",
    "convolutional",
    "denoising",
    "efficient data representations",
    "generative",
    "versus generative adversarial networks",
    "gans",
    "pca with undercomplete linear autoencoders",
    "probabilistic",
    "recurrent",
    "sparse",
    "stacked",
    "undercomplete",
    "unsupervised pretraining using stacked",
    "variational",
    "bayesian inference",
    "convolutional autoencoders",
    "mean squared error",
    "fashion mnist dataset",
    "visualizing fashion mnist dataset",
    "visualizing reconstructions",
    "decoders",
    "deep autoencoders",
    "deep convolutional gans",
    "denoising autoencoders",
    "discriminators",
    "encoders",
    "equalized learning rates",
    "experience replay",
    "generative adversarial networks",
    "dcgans",
    "difficulties of training",
    "stylegans",
    "generative autoencoders",
    "generative network",
    "generators",
    "greedy layer-wise training",
    "learning rate",
    "stacked autoencoders",
    "latent loss",
    "minibatch standard deviation layer",
    "linear autoencoders",
    "mean coding",
    "minibatch discrimination",
    "mixing regularization",
    "mode collapse",
    "nash equilibrium",
    "normalization",
    "overcomplete autoencoders",
    "pattern matching",
    "undercomplete linear autoencoders",
    "pixelwise normalization layers",
    "unsupervised pretraining",
    "using stacked autoencoders",
    "probabilistic autoencoders",
    "recognition network",
    "reconstruction loss",
    "reconstructions",
    "recurrent autoencoders",
    "reinforcement learning",
    "rl",
    "semantic interpolation",
    "sparse autoencoders",
    "sparsity",
    "sparsity loss",
    "stacked denoising autoencoders",
    "using keras",
    "style mixing",
    "style transfer",
    "tying weights",
    "undercomplete autoencoders",
    "pretraining using stacked autoencoders",
    "variational autoencoders"
  ],
  "18": [
    "ab experiments",
    "action advantage",
    "action step",
    "evaluating",
    "exploiting versus exploring",
    "actor-critic algorithms",
    "advantage actor-critic",
    "a2c",
    "asynchronous advantage actor-critic",
    "a3c",
    "dueling dqn algorithm",
    "genetic algorithms",
    "off-policy algorithms",
    "on-policy algorithms",
    "proximal policy optimization",
    "ppo",
    "reinforce algorithms",
    "soft actor-critic algorithm",
    "value iteration algorithm",
    "approximate q-learning",
    "atari preprocessing",
    "batched action step",
    "batched time step",
    "batched trajectory",
    "bellman optimality equation",
    "boundary transitions",
    "catastrophic forgetting",
    "collect policy",
    "mean squared error",
    "credit assignment problem",
    "curiosity-based exploration",
    "training loops",
    "datasets",
    "deep q-learning",
    "double dqn",
    "dueling dqn",
    "fixed q-value targets",
    "prioritized experience replay",
    "deep q-networks",
    "dqns",
    "deques",
    "discount factors",
    "double dueling dqn",
    "dqn agents",
    "dynamic programming",
    "exploration policy",
    "importance sampling",
    "is",
    "markov chains",
    "markov decision processes",
    "mdp",
    "installing",
    "observers",
    "online model",
    "openai gym",
    "optimal state value",
    "policies",
    "policy gradients",
    "pg",
    "policy parameters",
    "policy search",
    "policy space",
    "per",
    "q-learning",
    "approximate q-learning and deep q- learning",
    "implementing",
    "q-value iteration",
    "q-values",
    "queries per second",
    "qps",
    "rainbow agent",
    "evaluating actions",
    "neural network policies",
    "optimizing rewards",
    "temporal difference learning",
    "tf-agents library",
    "replay buffers",
    "replay memory",
    "sample inefficiency",
    "simulated environments",
    "state-action values",
    "stochastic policy",
    "target model",
    "td error",
    "td target",
    "td learning",
    "tensorflow model deployment at scale",
    "terminal state",
    "collect driver",
    "environment specifications",
    "environment wrappers",
    "environments",
    "replay buffer and observer",
    "training architecture",
    "training metrics",
    "trajectories",
    "trajectory",
    "undiscounted rewards"
  ],
  "19": [
    "active constraint",
    "ai platform",
    "allreduce algorithm",
    "dynamic placer algorithm",
    "boltzmann machines",
    "hopfield networks",
    "restricted boltzmann machines",
    "rbms",
    "self-organizing maps",
    "soms",
    "associative memory networks",
    "asynchronous updates",
    "automatic differentiation",
    "autodiff",
    "bandwidth saturation",
    "canary testing",
    "cluster specification",
    "colab runtime",
    "colaboratory",
    "colab",
    "complementary slackness",
    "compute unified device architecture library",
    "cuda",
    "concrete functions",
    "contrastive divergence",
    "cuda deep neural network library",
    "cudnn",
    "computing gradients using autodiff",
    "data parallelism",
    "data preparation",
    "deep belief networks",
    "dbns",
    "deep learning vm images",
    "distribution strategies api",
    "dual numbers",
    "dual problem",
    "embedded devices",
    "energy function",
    "data downloading",
    "data visualization",
    "framing the problem",
    "launching monitoring and maintaining",
    "machine learning project checklist",
    "model fine-tuning",
    "model selection and training",
    "exercise solutions",
    "fake quantization",
    "finite difference approximation",
    "forward-mode autodiff",
    "function definitions",
    "function graphs",
    "generalized lagrangian",
    "prediction service creation",
    "prediction service use",
    "google cloud storage",
    "gcs",
    "gpus",
    "graphics processing units",
    "gpu-equipped virtual machines",
    "managing gpu ram",
    "parallel execution across multiple devices",
    "placing operations and variables on devices",
    "selecting",
    "speeding computations with",
    "hidden units",
    "inequality constraints",
    "input signatures",
    "inter-op thread pool",
    "intra-op thread pool",
    "jupyterlab",
    "karushkuhntucker",
    "kkt",
    "lagrange multipliers",
    "logical gpu devices",
    "manual differentiation",
    "metagraphs",
    "mirrored strategy",
    "ml engine",
    "mobile devices",
    "model parallelism",
    "training across multiple devices",
    "stochastic neurons",
    "newtons difference quotient",
    "nvidia collective communications library",
    "nccl",
    "nvidia gpu cards",
    "parameter servers",
    "post-training quantization",
    "creating on gcp ai",
    "quantization-aware training",
    "queues",
    "ragged tensors",
    "reverse-mode autodiff",
    "savedmodel format",
    "service account",
    "sets",
    "spare replicas",
    "sparse tensors",
    "spurious patterns",
    "stale gradients",
    "stationary point",
    "string tensors",
    "symbolic differentiation",
    "symbolic tensors",
    "synchronous updates",
    "temperature",
    "tensor arrays",
    "tensorflow cluster",
    "special data structures",
    "autograph and tracing",
    "deploying to mobile and embedded devices",
    "serving tensorflow models",
    "training models across multiple devices",
    "using gpus to speed computations",
    "graphs generated by",
    "thermal equilibrium",
    "virtual gpu devices",
    "visible units",
    "warmup phase"
  ]
}